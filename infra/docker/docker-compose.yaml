services:
  # PostgreSQL Database - Optimized for Apple Silicon M4
  postgres:
    container_name: niki-postgres
    image: bitnami/postgresql:16
    platform: linux/amd64 # Explicit platform for M4 compatibility
    environment:
      POSTGRESQL_PASSWORD: ${POSTGRESQL_PASSWORD:-postgres123}
      POSTGRESQL_USERNAME: ${POSTGRESQL_USERNAME:-postgres}
      POSTGRESQL_DATABASE: ${POSTGRESQL_DATABASE:-app_db}
      POSTGRESQL_TIMEZONE: America/Sao_Paulo
      POSTGRESQL_MAX_CONNECTIONS: 100 # Reduced for development
      POSTGRESQL_SHARED_BUFFERS: 128MB # Optimized for M4
      POSTGRESQL_EFFECTIVE_CACHE_SIZE: 512MB
      POSTGRESQL_WORK_MEM: 4MB
      POSTGRESQL_MAINTENANCE_WORK_MEM: 32MB
    volumes:
      - postgres_data:/bitnami/postgresql
      - ./postgres/init-databases.sql:/docker-entrypoint-initdb.d/init-databases.sql:ro
    ports:
      - '${POSTGRESQL_PORT:-5432}:5432'
    restart: unless-stopped
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${POSTGRESQL_USERNAME:-postgres} -d ${POSTGRESQL_DATABASE:-app_db}']
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512MB
        reservations:
          cpus: '0.2'
          memory: 256MB
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  # Zookeeper - Optimized for Apple Silicon M4
  zookeeper:
    container_name: niki-zookeeper
    image: confluentinc/cp-zookeeper:7.6.1
    platform: linux/amd64
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    ports:
      - '2181:2181'
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 256MB
        reservations:
          cpus: '0.1'
          memory: 128MB
    volumes:
      - zookeeper_data:/tmp/zookeeper-logs
    healthcheck:
      test: ['CMD-SHELL', 'echo ruok | nc localhost 2181 || exit 1']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  # Kafka - Optimized for Apple Silicon M4
  kafka:
    container_name: niki-kafka
    image: confluentinc/cp-kafka:7.6.1
    platform: linux/amd64
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - '9092:9092'
      - '9094:9094'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENERS: INTERNAL://:9092,OUTSIDE://:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
    restart: unless-stopped
    volumes:
      - kafka_data:/tmp/kafka-logs
    healthcheck:
      test: ['CMD-SHELL', 'kafka-topics --bootstrap-server localhost:9092 --list || exit 1']
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.8'
          memory: 1GB
        reservations:
          cpus: '0.3'
          memory: 512MB
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  # Schema Registry - Schema management for Kafka
  schema-registry:
    container_name: niki-schema-registry
    image: confluentinc/cp-schema-registry:7.6.1
    platform: linux/amd64
    hostname: schema-registry
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - '8081:8081'
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'kafka:9092'
      SCHEMA_REGISTRY_LISTENERS: 'http://0.0.0.0:8081'
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
      SCHEMA_REGISTRY_DEBUG: 'false'
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: backward
    restart: unless-stopped
    volumes:
      - kafka_schema_registry_data:/tmp/schema-registry-logs
    healthcheck:
      test: ['CMD-SHELL', 'curl -f http://localhost:8081/subjects || exit 1']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512MB
        reservations:
          cpus: '0.2'
          memory: 256MB
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  # Control Center - Optional monitoring interface
  control-center:
    container_name: niki-control-center
    image: confluentinc/cp-enterprise-control-center:7.6.1
    platform: linux/amd64
    hostname: control-center
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - '9021:9021'
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_CONNECT_CLUSTER: http://kafka-connect:8083
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      PORT: 9021
      CONTROL_CENTER_STREAMS_NUM_STREAM_THREADS: 2
      CONTROL_CENTER_STREAMS_CACHE_MAX_BYTES_BUFFERING: 10485760

      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'http://kafka-connect:8083'
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONTROL_CENTER_CONNECT_HEALTHCHECK_ENDPOINT: '/connectors'
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
    restart: unless-stopped
    volumes:
      - kafka_control_center_data:/tmp/control-center-logs
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1GB
        reservations:
          cpus: '0.2'
          memory: 512MB
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  # Kafka Connect - Stream processing and connectors
  kafka-connect:
    container_name: niki-kafka-connect
    image: confluentinc/cp-kafka-connect-base:7.5.10
    platform: linux/amd64
    hostname: kafka-connect
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - '8083:8083'
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-connect'
      CONNECT_LOG4J_ROOT_LOGLEVEL: 'INFO'
      CONNECT_LOG4J_LOGGERS: 'org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR'
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: '[%d] %p %X{connector.context}%m (%c:%L)%n'
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: '1'
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components,/data/connect-jars
    command:
      - bash
      - -c
      - |
        echo "Installing Connector"
        confluent-hub install --no-prompt confluentinc/kafka-connect-elasticsearch:14.1.5
        #
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &
        #
        sleep infinity
    volumes:
      - kafka_connect_data:/tmp/connect-logs
    restart: unless-stopped
    healthcheck:
      test: ['CMD-SHELL', 'curl -f http://localhost:8083/connectors || exit 1']
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.8'
          memory: 1GB
        reservations:
          cpus: '0.3'
          memory: 512MB
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  # elasticsearch:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:7.11.2
  #   container_name: niki-elasticsearch
  #   hostname: elasticsearch
  #   environment:
  #     - node.name=niki-elasticsearch
  #     - cluster.name=niki-elasticsearch-cluster
  #     - cluster.initial_master_nodes=niki-elasticsearch
  #     - bootstrap.memory_lock=true
  #     - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
  #   ulimits:
  #     memlock:
  #       soft: -1
  #       hard: -1
  #   volumes:
  #     - elasticsearch_data:/usr/share/elasticsearch/data
  #   ports:
  #     - 9200:9200

  # kibana:
  #   image: docker.elastic.co/kibana/kibana:7.11.2
  #   container_name: niki-kibana
  #   hostname: kibana
  #   platform: linux/amd64
  #   ports:
  #     - 5601:5601
  #   environment:
  #     ELASTICSEARCH_URL: http://niki-elasticsearch:9200
  #     ELASTICSEARCH_HOSTS: '["http://niki-elasticsearch:9200"]'
  #   volumes:
  #     - kibana_data:/usr/share/kibana/data

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.0
    container_name: niki-elasticsearch
    platform: linux/arm64
    environment:
      - discovery.type=single-node
      - cluster.name=niki-cluster
      - node.name=elasticsearch
      - bootstrap.memory_lock=true
      # - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - xpack.monitoring.collection.enabled=true
      # - indices.memory.index_buffer_size=20%
      # - ELASTIC_PASSWORD=${ELASTICSEARCH_PASSWORD:-password123}
      - indices.queries.cache.size=15%
      - indices.fielddata.cache.size=25%
      - thread_pool.write.queue_size=1000
      - http.cors.enabled=true
      - action.destructive_requires_name=true
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      # - elasticsearch_logs:/usr/share/elasticsearch/logs
    ports:
      - '${ELASTICSEARCH_PORT:-9200}:9200'
      - '9300:9300'
    restart: unless-stopped
    healthcheck:
      test:
        ['CMD-SHELL', 'curl -s -f http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=5s || exit 1']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Kibana - Visualization for Elasticsearch
  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.0
    container_name: niki-kibana
    platform: linux/arm64
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - '${KIBANA_PORT:-5601}:5601'
    environment:
      - ELASTICSEARCH_HOSTS="http://elasticsearch:9200"
      - NODE_OPTIONS=--max-old-space-size=8192
      # - ELASTICSEARCH_USERNAME=kibana_system
      # - ELASTICSEARCH_PASSWORD=${ELASTICSEARCH_PASSWORD:-password123}
    volumes:
      - kibana_data:/usr/share/kibana/data
    restart: unless-stopped
    healthcheck:
      test: ['CMD-SHELL', 'curl -s -f http://localhost:5601/api/status || exit 1']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512MB
        reservations:
          cpus: '0.2'
          memory: 256MB

volumes:
  postgres_data:
    driver: local
    name: niki-postgres-data

  elasticsearch_data:
    driver: local
    name: niki-elasticsearch-data

  connect_data:
    driver: local
    name: niki-connect-data

  kibana_data:
    driver: local
    name: niki-kibana-data

  kafka_control_center_data:
    driver: local
    name: niki-kafka-control-center-data

  kafka_schema_registry_data:
    driver: local
    name: niki-kafka-schema-registry-data

  kafka_connect_data:
    driver: local
    name: niki-kafka-connect-data

  kafka_data:
    driver: local
    name: niki-kafka-data

  zookeeper_data:
    driver: local
    name: niki-zookeeper-data
